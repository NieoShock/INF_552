{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bo Yang (Aaron) USCID:7526922531"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### INF 552 HOMEWORK_7  Date: 12-01-2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generative Models for Text\n",
    "\n",
    "## (a) In this problem, we are trying to build a generative model to mimic the writing style of prominent British Mathematician, Philosopher, prolific writer, and political activist, Bertrand Russell."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) Download the following books from Project Gutenberg http://www.gutenberg.org/ebooks/author/355 in text format:\n",
    "- i. The Problems of Philosophy\n",
    "- ii. The Analysis of Mind\n",
    "- iii. Mysticism and Logic and Other Essays\n",
    "- iv. Our Knowledge of the External World as a Field for Scientific Method in Philosoph\n",
    "\n",
    "Project Gutenberg adds a standard header and footer to each book and this is not part of the original text. Open the file in a text editor and delete the header and footer.\n",
    "\n",
    "The header is obvious and ends with the text:<br>\n",
    "\\*** <b>START OF THIS PROJECT GUTENBERG EBOOK AN INQUIRY INTO MEANING AND TRUTH</b> \\***<br>\n",
    "The footer is all of the text after the line of text that says:<br>\n",
    "<b>THE END</b>\n",
    "\n",
    "To have a better model, it is strongly recommended that you download the following books from The Library of Congress https://archive.org and convert them to text files:\n",
    "- i. The History of Western Philosophy https://archive.org/details/westernphilosophy4\n",
    "- ii. The Analysis of Matter https://archive.org/details/in.ernet.dli.2015.221533\n",
    "- iii. An Inquiry into Meaning and Truth https://archive.org/details/BertrandRussell-AnInquaryIntoMeaningAndTruth\n",
    "<br>\n",
    "\n",
    "Try to only use the text of the books and throw away unwanted text before and after the text, although in a large corpus, these are considered as noise and should not make big problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) LSTM: Train an LSTM to mimic Russell’s style and thoughts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Concatenate your text files to create a corpus of Russell’s writings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sklearn's version is 0.21.3\n",
      "tensorflow's version is 2.0.0-alpha0\n",
      "tensorflow.python.keras.api._v2.keras's version is 2.2.4-tf\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "import copy\n",
    "\n",
    "for module in sklearn, tf, keras:\n",
    "    print(\"{}'s version is {}\".format(module.__name__, module.__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_PATH = \"./assets\"\n",
    "SPLASH = \"/\"\n",
    "PART_DATA_FILES = \"partbks/\"\n",
    "ALL_DATA_FILES = \"books/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import os\n",
    "\n",
    "def gen_corpus(file_pathes, output_file_name=\"CORPIS.txt\"):\n",
    "    dataFiles = os.listdir(file_pathes)\n",
    "    resultFile = open(output_file_name, 'w')\n",
    "    for fileItem in dataFiles:\n",
    "        with open(file_pathes + SPLASH + fileItem, 'r', \n",
    "                  encoding='ascii', errors='ignore') as fileDataStream:\n",
    "            for line in fileDataStream:\n",
    "                resultFile.write(line)\n",
    "\n",
    "    resultFile.close()\n",
    "    return resultFile.name\n",
    "\n",
    "\n",
    "def gen_chars_set(orginalText, ignore_case=False, remove_punctuation=False):\n",
    "    trimedText = copy.copy(orginalText)\n",
    "    charSet = set(orginalText)\n",
    "    if ignore_case:\n",
    "        trimedText = orginalText.lower()\n",
    "        charSet = set(orginalText.lower())\n",
    "    if remove_punctuation:\n",
    "        charSet = charSet.difference(set(string.punctuation))\n",
    "        trimedText = trimedText.translate(str.maketrans('', '', string.punctuation))\n",
    "    return trimedText, charSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of corpus of Russell's writing is:  5095252\n"
     ]
    }
   ],
   "source": [
    "resultFile = gen_corpus(ROOT_PATH + SPLASH + ALL_DATA_FILES)\n",
    "contents = open(resultFile, 'r').read()\n",
    "print(\"The length of corpus of Russell's writing is: \", len(contents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Use a character-level representation for this model by using extended ASCII that has N = 256 characters. Each character will be encoded into a an integer using its ASCII code. Rescale the integers to the range [0, 1], because LSTM uses a sigmoid activation function. LSTM will receive the rescaled integers as its input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------The original dict of distinct characters with its ascii is: --------------\n",
      " [('\\n', 0), (' ', 1), ('0', 2), ('1', 3), ('2', 4), ('3', 5), ('4', 6), ('5', 7), ('6', 8), ('7', 9), ('8', 10), ('9', 11), ('a', 12), ('b', 13), ('c', 14), ('d', 15), ('e', 16), ('f', 17), ('g', 18), ('h', 19), ('i', 20), ('j', 21), ('k', 22), ('l', 23), ('m', 24), ('n', 25), ('o', 26), ('p', 27), ('q', 28), ('r', 29), ('s', 30), ('t', 31), ('u', 32), ('v', 33), ('w', 34), ('x', 35), ('y', 36), ('z', 37)]\n",
      "--------------The scaled dict of distinct characters with its ascii is: --------------\n",
      " [('\\n', 0.0), (' ', 0.02702702702702703), ('0', 0.05405405405405406), ('1', 0.08108108108108109), ('2', 0.10810810810810811), ('3', 0.13513513513513514), ('4', 0.16216216216216217), ('5', 0.1891891891891892), ('6', 0.21621621621621623), ('7', 0.24324324324324326), ('8', 0.2702702702702703), ('9', 0.2972972972972973), ('a', 0.32432432432432434), ('b', 0.35135135135135137), ('c', 0.3783783783783784), ('d', 0.40540540540540543), ('e', 0.43243243243243246), ('f', 0.4594594594594595), ('g', 0.4864864864864865), ('h', 0.5135135135135136), ('i', 0.5405405405405406), ('j', 0.5675675675675675), ('k', 0.5945945945945946), ('l', 0.6216216216216217), ('m', 0.6486486486486487), ('n', 0.6756756756756757), ('o', 0.7027027027027027), ('p', 0.7297297297297298), ('q', 0.7567567567567568), ('r', 0.7837837837837838), ('s', 0.8108108108108109), ('t', 0.8378378378378379), ('u', 0.8648648648648649), ('v', 0.8918918918918919), ('w', 0.918918918918919), ('x', 0.945945945945946), ('y', 0.972972972972973), ('z', 1.0)]\n",
      "--------------The reversed dict of distinct characters with its ascii is: --------------\n",
      " [(0, '\\n'), (1, ' '), (2, '0'), (3, '1'), (4, '2'), (5, '3'), (6, '4'), (7, '5'), (8, '6'), (9, '7'), (10, '8'), (11, '9'), (12, 'a'), (13, 'b'), (14, 'c'), (15, 'd'), (16, 'e'), (17, 'f'), (18, 'g'), (19, 'h'), (20, 'i'), (21, 'j'), (22, 'k'), (23, 'l'), (24, 'm'), (25, 'n'), (26, 'o'), (27, 'p'), (28, 'q'), (29, 'r'), (30, 's'), (31, 't'), (32, 'u'), (33, 'v'), (34, 'w'), (35, 'x'), (36, 'y'), (37, 'z')]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import operator\n",
    "\n",
    "trimmedContent, CharacterSet = gen_chars_set(contents, ignore_case=True, remove_punctuation=True)\n",
    "char2AsciiDict = dict()\n",
    "for index, char in enumerate(sorted(CharacterSet)):\n",
    "    char2AsciiDict[char] = index\n",
    "\n",
    "print(\"--------------The original dict of distinct characters with its ascii is: \n",
    "      --------------\\n\", sorted(char2AsciiDict.items(), key=operator.itemgetter(1)))\n",
    "scaledCharDict = dict()\n",
    "scaledValues = MinMaxScaler().fit_transform(np.array(list(char2AsciiDict.values())).reshape(-1, 1))\n",
    "for index in range(len(scaledValues)):\n",
    "    scaledCharDict[list(char2AsciiDict.keys())[index]] = scaledValues[index][0]\n",
    "\n",
    "print(\"--------------The scaled dict of distinct characters with its ascii is: \n",
    "      --------------\\n\", sorted(scaledCharDict.items(), key=operator.itemgetter(1)))\n",
    "\n",
    "ascii2CharDict = {v:k for k, v in char2AsciiDict.items()}\n",
    "print(\"--------------The reversed dict of distinct characters with its ascii is: \n",
    "      --------------\\n\", sorted(ascii2CharDict.items(), key=operator.itemgetter(1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Choose a window size, e.g., W = 100\n",
    "### iv. Inputs to the network will be the first W −1 = 99 characters of each sequence, and the output of the network will be the Wth character of the sequence. Basically, we are training the network to predict each character using the 99 characters that precede it. Slide the window in strides of S = 1 on the text. For example, if W = 5 and S = 1 and we want to train the network with the sequence ABRACADABRA, The first input to the network will be ABRA and the corresponding output will be C. The second input will be BRAC and the second output will be A, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "windowSize = 99\n",
    "X_data = []\n",
    "Y_char_data = []\n",
    "for i in range(0, len(trimmedContent) - windowSize, 1):\n",
    "    tempBlock = trimmedContent[i:i + windowSize]\n",
    "    theLastChar = trimmedContent[i + windowSize]\n",
    "    X_data.append([scaledCharDict[char] for char in tempBlock])\n",
    "    Y_char_data.append(char2AsciiDict[theLastChar])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### v. Note that the output has to be encoded using a one-hot encoding scheme with N = 256 (or less) elements. This means that the network reads integers, but outputs a vector of N = 256 (or less) elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4942256, 99, 1)\n",
      "(4942256, 38)\n"
     ]
    }
   ],
   "source": [
    "numBlocks = len(X_data)\n",
    "X_data = np.reshape(X_data, (numBlocks, windowSize, 1))\n",
    "Y_data = keras.utils.to_categorical(Y_char_data)\n",
    "print(X_data.shape)\n",
    "print(Y_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vi. Use a single hidden layer for the LSTM with N = 256 (or less) memory units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### vii. Use a Softmax output layer to yield a probability prediction for each of the characters between 0 and 1. This is actually a character classification problem with N classes. Choose log loss (cross entropy) as the objective function for the network (research what it means)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### viii. We do not use a test dataset. We are using the whole training dataset to learn the probability of each character in a sequence. We are not seeking for a very accurate model. Instead we are interested in a generalization of the dataset that can mimic the gist of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7fe1b8471a58>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "unified_lstm (UnifiedLSTM)   (None, 256)               264192    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 38)                9766      \n",
      "=================================================================\n",
      "Total params: 273,958\n",
      "Trainable params: 273,958\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "memory_units = 256\n",
    "\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.LSTM(units=memory_units,\n",
    "                      input_shape=(X_data.shape[1], X_data.shape[2])),\n",
    "    keras.layers.Dense(Y_data.shape[1], activation=\"softmax\"),\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-4))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ix. Choose a reasonable number of epochs for training, considering your computational power (e.g., 30, although the network will need more epochs to yield a better model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "4941696/4942256 [============================>.] - ETA: 0s - loss: 2.6819WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 444s 90us/sample - loss: 2.6819\n",
      "Epoch 2/30\n",
      "4942208/4942256 [============================>.] - ETA: 0s - loss: 2.5241WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 439s 89us/sample - loss: 2.5241\n",
      "Epoch 3/30\n",
      "4942208/4942256 [============================>.] - ETA: 0s - loss: 2.4181WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 439s 89us/sample - loss: 2.4181\n",
      "Epoch 4/30\n",
      "4942080/4942256 [============================>.] - ETA: 0s - loss: 2.3259WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 440s 89us/sample - loss: 2.3259\n",
      "Epoch 5/30\n",
      "4942080/4942256 [============================>.] - ETA: 0s - loss: 2.2497WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 439s 89us/sample - loss: 2.2497\n",
      "Epoch 6/30\n",
      "4942208/4942256 [============================>.] - ETA: 0s - loss: 2.1865WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 440s 89us/sample - loss: 2.1865\n",
      "Epoch 7/30\n",
      "4942208/4942256 [============================>.] - ETA: 0s - loss: 2.1323WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 438s 89us/sample - loss: 2.1323\n",
      "Epoch 8/30\n",
      "4941952/4942256 [============================>.] - ETA: 0s - loss: 2.0826WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 438s 89us/sample - loss: 2.0826\n",
      "Epoch 9/30\n",
      "4942208/4942256 [============================>.] - ETA: 0s - loss: 2.0390WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 438s 89us/sample - loss: 2.0390\n",
      "Epoch 10/30\n",
      "4941952/4942256 [============================>.] - ETA: 0s - loss: 2.0018WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 438s 89us/sample - loss: 2.0018\n",
      "Epoch 11/30\n",
      "4942080/4942256 [============================>.] - ETA: 0s - loss: 1.9689WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 438s 89us/sample - loss: 1.9689\n",
      "Epoch 12/30\n",
      "4941952/4942256 [============================>.] - ETA: 0s - loss: 1.9402WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 438s 89us/sample - loss: 1.9402\n",
      "Epoch 13/30\n",
      "4942080/4942256 [============================>.] - ETA: 0s - loss: 1.9146WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 438s 89us/sample - loss: 1.9146\n",
      "Epoch 14/30\n",
      "4942208/4942256 [============================>.] - ETA: 0s - loss: 1.8917WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 437s 89us/sample - loss: 1.8917\n",
      "Epoch 15/30\n",
      "4942208/4942256 [============================>.] - ETA: 0s - loss: 1.8709WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 438s 89us/sample - loss: 1.8709\n",
      "Epoch 16/30\n",
      "4941952/4942256 [============================>.] - ETA: 0s - loss: 1.8519WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 438s 89us/sample - loss: 1.8519\n",
      "Epoch 17/30\n",
      "4942208/4942256 [============================>.] - ETA: 0s - loss: 1.8344WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 438s 89us/sample - loss: 1.8344\n",
      "Epoch 18/30\n",
      "4942080/4942256 [============================>.] - ETA: 0s - loss: 1.8184WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 439s 89us/sample - loss: 1.8184\n",
      "Epoch 19/30\n",
      "4942080/4942256 [============================>.] - ETA: 0s - loss: 1.8035WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 438s 89us/sample - loss: 1.8035\n",
      "Epoch 20/30\n",
      "4941952/4942256 [============================>.] - ETA: 0s - loss: 1.7898WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 438s 89us/sample - loss: 1.7898\n",
      "Epoch 21/30\n",
      "4942208/4942256 [============================>.] - ETA: 0s - loss: 1.7768WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 438s 89us/sample - loss: 1.7768\n",
      "Epoch 22/30\n",
      "4941952/4942256 [============================>.] - ETA: 0s - loss: 1.7648WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 438s 89us/sample - loss: 1.7648\n",
      "Epoch 23/30\n",
      "4942208/4942256 [============================>.] - ETA: 0s - loss: 1.7535WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 438s 89us/sample - loss: 1.7535\n",
      "Epoch 24/30\n",
      "4941824/4942256 [============================>.] - ETA: 0s - loss: 1.7429WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 438s 89us/sample - loss: 1.7429\n",
      "Epoch 25/30\n",
      "4942208/4942256 [============================>.] - ETA: 0s - loss: 1.7329WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 438s 89us/sample - loss: 1.7329\n",
      "Epoch 26/30\n",
      "4942208/4942256 [============================>.] - ETA: 0s - loss: 1.7233WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 439s 89us/sample - loss: 1.7233\n",
      "Epoch 27/30\n",
      "4942080/4942256 [============================>.] - ETA: 0s - loss: 1.7141WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 437s 88us/sample - loss: 1.7141\n",
      "Epoch 28/30\n",
      "4942080/4942256 [============================>.] - ETA: 0s - loss: 1.7054WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 437s 89us/sample - loss: 1.7054\n",
      "Epoch 29/30\n",
      "4942080/4942256 [============================>.] - ETA: 0s - loss: 1.6971WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 437s 88us/sample - loss: 1.6971\n",
      "Epoch 30/30\n",
      "4942080/4942256 [============================>.] - ETA: 0s - loss: 1.6892WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 436s 88us/sample - loss: 1.6892\n"
     ]
    }
   ],
   "source": [
    "epochs = 30\n",
    "output_dir = \"./text_generation_checkpoint1\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    \n",
    "checkpoint_prefix = os.path.join(output_dir, 'ck_{epoch:02d}.hdf5')\n",
    "checkpoint_callback = keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_prefix,\n",
    "    monitor='loss',\n",
    "    save_weights_only= True,\n",
    "    mode='min'\n",
    ")\n",
    "earlyStoppingCk = keras.callbacks.EarlyStopping(patience = 5, min_delta = 1e-4)\n",
    "history = model.fit(X_data, Y_data, epochs=epochs, batch_size=128, \n",
    "                    callbacks=[checkpoint_callback, earlyStoppingCk])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### x. Use model checkpointing to keep the network weights to determine each time an improvement in loss is observed at the end of the epoch. Find the best set of weights in terms of loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "minLossCheckPoint = output_dir +'/ck_30.hdf5'\n",
    "model.load_weights(minLossCheckPoint)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xi. Use the network with the best weights to generate 1000 characters, using the following text as initialization of the network:\n",
    "    \"There are those who take mental phenomena naively, just as they\n",
    "    would physical phenomena. This school of psychologists tends not to\n",
    "    emphasize the object.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "initText = 'There are those who take mental phenomena naively, just as they would physical phenomena. This school of psychologists tends not to emphasize the object.'\n",
    "initText = initText.translate(str.maketrans('', '', string.punctuation))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are those who take mental phenomena naively just as they would physical phenomena this school of psychologists tends not to emphasize the object much exposure to content there  to be any way to control of the semse and the semse of the \n",
      "perception of the semse in the sense of the soace and the \n",
      "content of the soace and the soace and the soace and the soace of the content of the soace \n",
      "of the soace and the soace and the soace and the soace and the \n",
      "\n",
      "\n",
      "\n",
      "170  \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "genText = copy.copy(initText.lower())\n",
    "encodeList = [scaledCharDict[char] for char in genText][-99:]\n",
    "for _ in range(1000):\n",
    "    data = np.reshape(encodeList, (1, len(encodeList), 1))\n",
    "    pred = model.predict(data)\n",
    "    charIndex = np.argmax(pred)\n",
    "    char = ascii2CharDict[np.argmax(pred)]\n",
    "    genText += char\n",
    "    encodeList.append(scaledCharDict[char])\n",
    "    encodeList = encodeList[1:len(encodeList)]\n",
    "    \n",
    "print(genText)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xii. Extra Practice: Use one-hot encoding for the input sequence. Use a large number of epochs, e.g., 150. Add dropout to the network, and use a deeper LSTM (e.g. with 3 or more layers). Generate 3000 characters using the above initialization and report if you get more meaningful text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f6328577b00>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f62872c6898>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "WARNING:tensorflow:<tensorflow.python.keras.layers.recurrent.UnifiedLSTM object at 0x7f62815ad7b8>: Note that this layer is not optimized for performance. Please use tf.keras.layers.CuDNNLSTM for better performance on GPU.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "unified_lstm (UnifiedLSTM)   (None, 99, 256)           264192    \n",
      "_________________________________________________________________\n",
      "unified_lstm_1 (UnifiedLSTM) (None, 99, 256)           525312    \n",
      "_________________________________________________________________\n",
      "unified_lstm_2 (UnifiedLSTM) (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 38)                9766      \n",
      "=================================================================\n",
      "Total params: 1,324,582\n",
      "Trainable params: 1,324,582\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = keras.models.Sequential([\n",
    "    keras.layers.LSTM(units=memory_units,\n",
    "                      input_shape=(X_data.shape[1], X_data.shape[2]), \n",
    "                      return_sequences=True),\n",
    "    \n",
    "    keras.layers.LSTM(units=memory_units, return_sequences=True),\n",
    "    keras.layers.LSTM(units=memory_units, return_sequences=False),\n",
    "    keras.layers.Dense(Y_data.shape[1], activation=\"softmax\"),\n",
    "])\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-4))\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 2.5841WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 696s 141us/sample - loss: 2.5840\n",
      "Epoch 2/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 2.4900WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 696s 141us/sample - loss: 2.4899\n",
      "Epoch 3/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 2.3661WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 696s 141us/sample - loss: 2.3660\n",
      "Epoch 4/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 2.2419WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 696s 141us/sample - loss: 2.2418\n",
      "Epoch 5/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 2.1290WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 695s 141us/sample - loss: 2.1290\n",
      "Epoch 6/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 2.0347WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 695s 141us/sample - loss: 2.0347\n",
      "Epoch 7/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.9566WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 695s 141us/sample - loss: 1.9565\n",
      "Epoch 8/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.8915WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 696s 141us/sample - loss: 1.8915\n",
      "Epoch 9/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.8359WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 696s 141us/sample - loss: 1.8359\n",
      "Epoch 10/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.7877WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 695s 141us/sample - loss: 1.7877\n",
      "Epoch 11/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.7448WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 695s 141us/sample - loss: 1.7448\n",
      "Epoch 12/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.7064WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 695s 141us/sample - loss: 1.7064\n",
      "Epoch 13/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.6717WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 695s 141us/sample - loss: 1.6717\n",
      "Epoch 14/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.6393WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 695s 141us/sample - loss: 1.6393\n",
      "Epoch 15/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.6096WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 695s 141us/sample - loss: 1.6096\n",
      "Epoch 16/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.5839WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 696s 141us/sample - loss: 1.5839\n",
      "Epoch 17/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.5609WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 695s 141us/sample - loss: 1.5608\n",
      "Epoch 18/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.5402WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 695s 141us/sample - loss: 1.5402\n",
      "Epoch 19/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.5210WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 695s 141us/sample - loss: 1.5210\n",
      "Epoch 20/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.5035WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 695s 141us/sample - loss: 1.5035\n",
      "Epoch 21/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.4871WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 695s 141us/sample - loss: 1.4871\n",
      "Epoch 22/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.4696WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 695s 141us/sample - loss: 1.4696\n",
      "Epoch 23/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.4524WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 696s 141us/sample - loss: 1.4524\n",
      "Epoch 24/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.4385WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 695s 141us/sample - loss: 1.4385\n",
      "Epoch 25/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.4257WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 695s 141us/sample - loss: 1.4256\n",
      "Epoch 26/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.4138WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 695s 141us/sample - loss: 1.4138\n",
      "Epoch 27/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.4024WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 696s 141us/sample - loss: 1.4024\n",
      "Epoch 28/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.3918WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 696s 141us/sample - loss: 1.3918\n",
      "Epoch 29/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.3820WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 696s 141us/sample - loss: 1.3820\n",
      "Epoch 30/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.3725WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 696s 141us/sample - loss: 1.3726\n",
      "Epoch 31/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.3636WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 696s 141us/sample - loss: 1.3636\n",
      "Epoch 32/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.3551WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 696s 141us/sample - loss: 1.3551\n",
      "Epoch 33/100\n",
      "4939776/4942256 [============================>.] - ETA: 0s - loss: 1.3475WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss\n",
      "4942256/4942256 [==============================] - 696s 141us/sample - loss: 1.3475\n",
      "Epoch 34/100\n",
      "2457600/4942256 [=============>................] - ETA: 5:49 - loss: 1.3415"
     ]
    }
   ],
   "source": [
    "epochs = 100\n",
    "output_dir = \"./text_generation_checkpoint2\"\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "    \n",
    "checkpoint_prefix2 = os.path.join(output_dir, 'ck_{epoch:02d}.hdf5')\n",
    "checkpoint_callback2 = keras.callbacks.ModelCheckpoint(\n",
    "    filepath = checkpoint_prefix2,\n",
    "    monitor='loss',\n",
    "    save_weights_only= True,\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "history2 = model2.fit(X_data, Y_data, epochs=epochs, batch_size=4096, \n",
    "                      callbacks=[checkpoint_callback2, earlyStoppingCk])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "minLossCheckPoint = output_dir +'/ck_33.hdf5'\n",
    "model2.load_weights(minLossCheckPoint)\n",
    "model2.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(1e-4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there are those who take mental phenomena naively just as they would physical phenomena this school of psychologists tends not to emphasize the object much exposure to content there to be any way to control of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense of the sense\n"
     ]
    }
   ],
   "source": [
    "genText2 = copy.copy(initText.lower())\n",
    "encodeList2 = [scaledCharDict[char] for char in genText2][-99:]\n",
    "for _ in range(3000):\n",
    "    data2 = np.reshape(encodeList2, (1, len(encodeList2), 1))\n",
    "    pred2 = model2.predict(data2)\n",
    "    charIndex2 = np.argmax(pred2)\n",
    "    char2 = ascii2CharDict[charIndex2]\n",
    "    genText2 += char2\n",
    "    encodeList2.append(scaledCharDict[char2])\n",
    "    encodeList2 = encodeList2[1:len(encodeList2)]\n",
    "    \n",
    "print(genText2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xiii. Extra Practice- HMM: Train a Hidden Markov Model with V hidden states and V possible outputs using Baum-Welch Algorithm (or any other modern algorithm that is available) with the Russell corpus, where V is the number of distinct words in the corpus. Note that for HMM, you NOT use character level encoding, because it may yield totally meaningless results, although the transition matrices associated with it will be way smaller (you are welcome to try it). Generate 200 words using the model and comment on its meaningfulness. Extra extra practice: can you train a higher order HMM (i.e. an HMM that assumes dependency on more than one previous state) to get a better model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
